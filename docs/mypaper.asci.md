Unsupervised image classification and latent representation


Ali  
Received: XX Month 202X; Accepted: XX Month 202X 
Abstract: Image classification in the field of medical imaging, significantly, relies on supervised learning. However, supervised learning faces challenges such as limited labeled data, model complexity, and difficulties in interpreting model predictions. Some of these challenges can be overcome by adopting unsupervised learning, but the accuracy of unsupervised learning should be addressed.  In this study, we introduce an approach that integrates pre-trained models with clustering methodologies, achieving notable accuracy in unsupervised image classification. The image encodings are plotted in 2D to show some degree of separation in the low-dimensional manifold. Various state-of-the-art models, such as ResNet and DenseNet, are used to obtain image encodings, and classical approaches, such as convolutional autoencoders and scale-invariant feature transform (SIFT) with a histogram of gradients (HOG). The results are reported on the CIFAR-10 dataset, and a decent, maximum accuracy of 68.14% is achieved on unsupervised image classification. The author(s) received no specific funding for this study.

Keywords: Unsupervised learning, ResNet and DenseNet, CIFAR-10 dataset.
1	Introduction
    Image classification plays a pivotal role in medical imaging, offering valuable insights into the content of medical images. Algorithms like Convolutional Neural Networks (CNNs) (see list of acronyms in appendix) offer rapid and precise classification of medical images across different categories. Additionally, clustering techniques can group alike medical images, aiding in pattern recognition. [1]. Adopting such technologies can enhance diagnostic accuracy and efficiency for medical professionals. Convolutional Neural Networks (CNNs) are commonly employed machine learning algorithms for image classification. These algorithms are trained on large datasets of medical images to learn patterns and classify images into various categories [1, 2]. By using these algorithms, medical professionals can quickly and accurately detect abnormalities in medical scans. This can be beneficial for diagnosing conditions and saving time for physicians.
    Supervised and unsupervised image classification are two important techniques used for medical image analysis. Supervised image classification involves categorizing a medical image into different classes based on the presence of certain features or characteristics. This type of classification is often used to detect abnormal tissue or organs, such as tumors or blood vessels. The model used for supervised image classification is often a supervised machine learning algorithm. It uses a training dataset with labeled data to learn how to classify the images [3]. Unsupervised image classification, on the other hand, is a method of analyzing medical images without the need for labeled data. Instead, the algorithm looks for patterns or features present in the image and assigns labels accordingly. This type of classification is often used to analyze tissue segments in medical images, such as organ boundaries or muscle tissue. The most common model used for unsupervised image classification is clustering, which is used to group similar objects or areas.
    Supervised learning in medical imaging uses labeled data to build a model that can accurately predict the outcome of a given input. The most commonly used algorithms for supervised learning are decision trees, logistic regression, linear regression, and support vector machines. A decision tree is used to classify data points into different categories. Logistic regression and linear regression are used to find the relationship between two variables, while a support vector machine is used to build a model that predicts the output based on the given input [3,5]  Unsupervised learning in medical imaging uses unlabeled data to detect patterns and structure in the data. The most commonly used algorithms for unsupervised learning are k-means clustering, hierarchical clustering, and apriori algorithm. K-means clustering is used to group similar data points into clusters. Hierarchical clustering is used to generate clusters from a hierarchy of clusters. Apriori algorithm is used to identify frequent patterns in the data [6]. All these algorithms are used to uncover patterns and structures in the data that can be used for medical diagnosis and treatments. Both supervised and unsupervised image classification is important techniques for medical imaging. While supervised classification requires labeled data, unsupervised classification requires no labeled data, making it useful for analyzing medical images without any prior knowledge about the image [4]. Furthermore, both methods can be used to detect abnormalities or to segment and classify tissues in medical images but supervised methods are significantly more labor intensive. Conversely, unsupervised learning techniques attain significantly lower accuracy than supervised methods, necessitating further research. 
    In recent years, semi-supervised learning (SSL) [16] has emerged as an exciting new analysis direction in deep learning. Such methods influence cases in which few labeled coaching examples are offered along with a large variety of unlabeled samples. In such a setting, SSL strategies are highly applicable to real-world applications in which the unlabeled knowledge is available and simple to accumulate, whereas labeled instances are typically exhausting, expensive, and require time to gather. SSL can build higher classifiers that atone for the dearth of labeled training knowledge. However, to avoid poor matter structure matching with the model assumption, which might cause degradation in classification performance, SSL is only effective under certain assumptions, such as presumptions that the choice boundary ought to avoid regions with high density, facilitating the extraction of extra information from the unlabeled instances to regularize coaching. We move beyond semi-supervised learning to completely unsupervised learning for image classification [12]. Most of the data in today’s world follow an unsupervised learning methodology, i.e., the labels are not present with all the data points.
    Obtaining labeled data is very often a painful process, so we propose an experimental approach for classifying images in an unsupervised manner where image encodings from pre-trained models are obtained and then clustering is applied to form an end-to-end unsupervised model. We discuss various pre-trained models, such as DenseNet [13] and ResNet [11], in this paper and show the encodings in 2D manifolds using the t-SNE dimensionality reduction technique [18]. The results are discussed on the CIFAR-10 dataset [8].
    SIFT with HOG [17] was also used as a feature extractor but did not yield good results along with convolutional autoencoders [21] and ResNets. The methodology for all these experiments was the same, i.e., extracting features and then using K-means to cluster the data. The basis of unsupervised learning is to obtain somewhat separable data and then perform clustering or any other unsupervised models. We show the learned features in 2D space to visualize the various classes present in the CIFAR-10 dataset and how they are somewhat separate after extracting the image encodings. This work can be extended to practical uses where state-of-the-art models can be deployed in an unsupervised manner to obtain good results with minimal effort to obtain labeled data.

2 Related Worked
       In this work, we present the current state of the art in both the semi-supervised and unsupervised learning fields. Supervised and unsupervised image classification are two methods for assigning labels to images. Supervised image classification relies on human experts to provide labels for a set of images; the labels are then used to train a model to classify new images. This approach is effective when labels are available and the goal is to classify images into discrete categories, but it is labor-intensive and limited by the number of labels provided [23]. Unsupervised image classification, on the other hand, seeks to identify patterns in the data without relying on labeled data. It is useful when labels are not available and when exploring the data for patterns. The unsupervised classification does not require labeled data and instead relies on the model’s ability to detect patterns in the data. This approach allows for more complex categorizations and can be used to identify unknown relationships between images. However, since it does not use labeled data, it can be more prone to errors and inaccuracies. [24]. consequentially, we consider semi-supervised learning as the most applicable progression in the field of medical imaging.
     Semi-supervised learning describes a class of algorithms that seek to learn from both unlabeled and labeled cross-sections, normally assumed to be tested from the same or parallel distributions. We concentrate on recent developments grounded on deep neural networks in medical imaging. Notably, semi-supervised learning in medical imaging through deep learning models presents several challenges. Firstly, medical images are often extremely high-dimensional, which can lead to several issues such as overfitting and computational complexity [25]. Moreover, the data used for training and validation can be highly imbalanced, which can lead to poor results due to the lack of enough data in certain classes [24, 26]. Additionally, the data used for training can also be very noisy, which can result in the learning algorithm being unable to accurately identify patterns in the data [26, 27].
     Attempts to overcome the challenges of semi-supervised learning involve proposing novel deep learning frameworks, such as the Attention-based Semi-supervised Deep Networks (ASDNet), to fulfill segmentation tasks in an end-to-end fashion [28]. This framework includes a convolutional confidence network that is used to adversarially train the segmentation network and a region-attention-based semi-supervised learning strategy that allows for the inclusion of unlabeled data for training. Such methods can help to alleviate the need for labor-intensive ground-truth label maps and expertise knowledge.  Moreover, numerous of the original developments in semi-supervised learning deep neural networks were predicated on generative models similar to denoising autoencoders [15], variational autoencoders [12], and generative adversarial networks [20]. We used DenseNets and K-means clustering. DenseNet is used for feature extraction.
     Clustering [14] is a set of methodologies employed to partition data into groups or clusters. Clusters are approximately outlined as groups of data objects that are more analogous to other objects in their cluster than they are to data objects in other clusters. In practice, clustering helps identify two classes of data. Meaningful data expand the sphere of knowledge. For illustration, in the medical field, experimenters applied clustering to gene expression trials. The clustering results linked groups of cases who responded to medical treatments. Usefulness in clustering, in contrast, serves as a median step in a data channel. For illustration, businesses apply clustering for customer segmentation. The clustering results in clustering member guests into groups with similar purchase histories, which companies can also exercise to produce useful targeted advertising. Conventional K-means require many methods. The first step is to randomly select k centroids, where k is equal to the number of clusters chosen.
     Centroids are data points representing the center of a cluster. The main element of the algorithm works by a two-step process called expectation maximization. The expectation step assigns each data point to its nearest centroid. The maximization step computes the mean of all the points for each cluster and sets the new centroid. The quality of the cluster assignments is determined by calculating the sum of the squared error (SSE) after the centroids meet or match the former replication’s assignment. The SSE is defined as the sum of the squared Euclidean distances of each point to its closest centroid.  Since this is a measure of error, the ideal of K-means is to attempt to minimize this value. In our research, to map the clusters generated by the k-means algorithm to the true labels of the CIFAR-10 dataset, we employed the Hungarian algorithm, a combinatorial optimization technique. We constructed a cost matrix, where each element represents the negative count of instances from a particular class in a specific cluster. The negation was necessary as the Hungarian algorithm is inherently a minimization procedure, but our objective was maximization. Upon application of the algorithm to the cost matrix, we derived an optimal one-to-one mapping between clusters and true labels, ensuring the highest possible correspondence between clustered data and their actual classes. 
     DenseNets is a densely connected convolutional neural network [10] that is used more than a traditional CNN because DenseNet requires fewer parameters than a traditional CNN. This approach was specifically developed to improve performance and accuracy caused by the vanishing gradient, particularly in a high-level neural network, due to the long distance between the output and input layers causing the information to vanish before reaching its destination. In this paper, we specifically used DenseNet to extract features from images. Additionally, for parameter efficiency – every layer adds only a limited number of parameters, and implicit deep supervision – the improved flow of gradient through the network. CNNs are used to classify the CIFAR-10 dataset in an unsupervised manner, and the accuracy reported is approximately 70% [9]. KNNs are also used for CIFAR-10 classification with CNNs with supervised learning and good accuracy [7]. GANs and adversarial training with clustering has also been applied to similar datasets [16]. In our exploration of unsupervised image classification, we attained a commendable accuracy of 68.14% utilizing pre-trained models combined with clustering techniques. In comparison, the study by Caron et al. (2019) introduced the innovative DeepCluster algorithm, focusing on a convolutional neural network's feature clustering, While our method leveraged a straightforward approach of feature extraction followed by k-means clustering, Caron et al. emphasized a more intricate deep clustering mechanism, though exact performance metrics weren't explicitly stated in the extracted sections.
     The literature explored various advancements and techniques in unsupervised image classification. Significant emphasis has been given to the use of deep learning models, their evolution, and their application in real-world scenarios. While many models have shown promise, challenges in training, accuracy, and computational efficiency persist. The survey highlights a trend toward leveraging pre-trained models, which have shown to enhance performance. However, there remains a gap in achieving optimal accuracy, especially in complex datasets, underscoring the need for further research in this domain.
3 Contribution
    1. Introduction of a novel approach:
 The paper contributes to the field of image classification by introducing a novel approach that combines pre-trained models with clustering techniques for unsupervised image classification. This approach offers an alternative solution for situations where labeled data is scarce or unavailable.
    2. Evaluation of semi-supervised learning in medical imaging:
The paper explores the challenges and potential benefits of semi-supervised learning specifically in the context of medical imaging. By highlighting the difficulties associated with traditional supervised learning in this domain, the paper provides insights into the effectiveness of semi-supervised techniques for medical image classification.
    3. Development of Attention-based Semi-supervised Deep Networks (ASDNet): 
The paper presents the development of ASDNet, a deep learning framework that incorporates techniques like adversarial training and region-attention-based semi-supervised learning. This framework addresses the challenges of high dimensionality, imbalanced data, and noise commonly encountered in medical imaging datasets.
    4. Experimental evaluation:
 The paper conducts experiments to evaluate the proposed approach's performance. It reports an accuracy of 68.14% in unsupervised image classification using DenseNets and clustering. These experimental results contribute to the understanding of the effectiveness of pre-trained models combined with clustering techniques in image classification tasks.
    5. Visualization techniques: 
The paper employs visualization techniques, such as t-SNE, to visualize the lower-dimensional representations of image encodings obtained from pre-trained models. By visualizing these representations, the paper enhances the interpretability and understanding of the clustering results.
    6. Potential applications: 
The paper discusses potential applications of the unsupervised image classification approach in fields like intracavity absorption spectroscopy. By highlighting these applications, the paper opens up new avenues for research and encourages further exploration of the proposed approach in other domains.
    7. Comparative analysis: 
The paper compares the proposed approach with existing methods in image classification to showcase its advantages and limitations. This comparative analysis contributes to the existing body of knowledge by demonstrating the strengths and weaknesses of the proposed approach in relation to other techniques.
    8. Dataset availability: 
By making the dataset available on GitHub, the paper contributes to the research community by providing a valuable resource for others to replicate and build upon the findings. This promotes transparency, reproducibility, and collaboration within the field.
These contributions collectively enhance the understanding of unsupervised and semi-supervised image classification, specifically in the context of medical imaging. They provide valuable insights, techniques, and experimental results that can guide future research and advance the field.

4 Methodology 
The image encodings from pre-trained models such as ResNets and DenseNets were obtained and then clustered using K-means clustering. The main idea behind this approach is to reduce the input dimensions while maintaining some sort of information about the image and then producing the clusters in an unsupervised manner. Figure 2 displays the encoded representations of images using DenseNets. These encodings, originally in higher-dimensional space, have been transformed to a 3-dimensional space for visualization purposes using the t-SNE dimensionality reduction technique.  The image encodings are shown in Figure 2 below after reducing to 3 dimensions using t-SNE. As seen in the future, the image encodings shown are very distinct and are well-separated to some extent. This proves that the low- dimensional features extracted from the image were good enough to separate them to some extent. There are 10 classes in the CIFAR-10 dataset; hence, 10 color coding schemes are used.
The encodings were obtained from autoencoders as well, where the input image and the output image were the same and the convolutional autoencoder attempted to minimize the reconstruction loss. Figure 3 delineates the nuanced procedure adopted for unsupervised image classification leveraging deep learning architectures. The following elucidates the salient stages and technical intricacies:
4.1 Model Architecture Selection
A judicious examination of established deep learning architectures, notably ResNet and DenseNet, was undertaken. These architectures, benefitting from rigorous training on expansive datasets, facilitate potent feature extraction—imperative for the classification task at hand.
4.2 Architectural Depth and Configuration
DenseNet is characterized by a composite of dense blocks interspersed with transition layers. The precise depth, manifesting as the number of layers, is contingent upon the specific variant under consideration (e.g., DenseNet-121 or DenseNet-169). In this study ResNet-50 and DenseNet-201 were used.
Feature Extraction Paradigm
The primary endeavor entails capitalizing on the architectures to distill salient features from images within the CIFAR-10 dataset. This process necessitates the propagation of images through the network and the subsequent abstraction of feature maps from intermediary layers, which encapsulate intricate image patterns.
Unsupervised Clustering Mechanism 
Subsequent to the feature extraction phase, unsupervised algorithms, notably K-means, are employed to orchestrate the images into discernible clusters predicated on the extracted features. This stratification accords the categorization of images into discrete clusters, each emblematic of a distinct category.
Dimensionality Reduction via t-SNE
To facilitate an intuitive representation and discernment of the distinction between clusters, the high-dimensional feature vectors undergo a transformation to a 2D space using the t-SNE technique. This transformation offers an incisive visualization of cluster separation within this reduced feature space.

Figure 1 Illustration of the DenseNet Structure [28]


Figure 2 t-SNE generated 2D representation of image encodings extracted by pre-trained models.


Figure 3 t-SNE 2D representation of image encodings
     In figure 2, after extracting the image encodings the K-means algorithm is applied with k=10 because there are 10 classes in the dataset. Multiple K-means iterations are executed, and the best iteration is used for the results and evaluations. In the flowchart given below in Figure 3, the whole end-to-end process is explained. SIFT and HOG were used for feature extraction from images in an unsupervised manner. They were used to extract the features, such as landmarks and other local features, from the image. The features were computed after considering the gradient’s magnitude and direction. After extracting those features for the CIFAR-10 dataset, K-means clustering was applied similarly, and the results were obtained.

Figure 4 Flowchart of the whole process
5 Results and Discussion 
The CIFAR-10 dataset is a collection of images from 10 classes that can be used to train and assess the accuracy of unsupervised learning algorithms. It consists of 60,000 32x32 color images that are divided into 10 classes, with each class containing 6,000 images. The 10 classes represent common objects [28]. In terms of medical imaging applications, the CIFAR-10 dataset can be used to train and assess the accuracy of unsupervised learning algorithms in the diagnosis of certain diseases or conditions. The 10 classes can be mapped to different medical image features, such as X-rays, CT Scans, or MRI images. By training and testing the accuracy of unsupervised learning algorithms on the CIFAR-10 dataset, medical researchers can gain insight into the accuracy of unsupervised learning algorithms for diagnosing certain diseases or conditions.
In this study, we tried various unsupervised learning methods in this paper. The evaluation metric used to interpret the results was accuracy because of the balanced dataset. The accuracy was obtained by counting the same class of CIFAR-10 assigned to 1 cluster from the K-means algorithm. In the table given below, the results of our methods are shown. The accuracy is not very good because the model did not have labels to learn from. The dataset was divided into an 80-20 split i.e., 80% of the data was used for training, and 20% was used for testing. K-means was executed multiple times to obtain the results because of its stochastic nature.
Table 1 Test accuracy for different image encoding methods.
Image Encodings
Test Accuracy
Average Precision
Average Recall
AverageF1 Score
DenseNet
68.14%
58%
62%
57%
ResNet
22.47%
22%
24%
22%
SIFT and HOG
27.03%
24%
24%
24%
Convolutional Autoencoder
24.58%
22%
22%
22%
Various algorithms were used for unsupervised learning. In this paper, we compare the results with existing supervised methods for the CIFAR-10 dataset as shown in Table 2
Table 2  Comparing the proposed method with other algorithms based on the CIFAR-10 dataset
Method
Test Accuracy
Residual Network with Attention
96.10%
ConvNets for Rotation Prediction
89.90%
Invariant Image Clustering
61.7%
Our Method
68.14%

     Comparing the models indicate that the residual network with attention and convNets for rotation prediction has higher accuracy than the proposed model. However, our proposed model provided among the highest accuracy ratings for unsupervised learning in medical imaging because of the specific use case, and the pretraining was based on the CIFAR-10 datasets. For instance, pre-training done using Imagenet-1k was applied for deep convolutional generative adversarial networks (DGCAN) and used to classify CIFAR-10, yielding an accuracy of 63.7% for K=1 [29]. Thus, the attained accuracy is significantly higher than the previous works under the same CIFAR-1o datasets, but could be improved further, implying that the outcomes of this study lay a foundation for future improvements. 

5.1 Correlation with Intracavity Absorption Spectroscopy Studies
    Our work emphasizes unsupervised image classification using deep learning. Interestingly, recent studies in intracavity absorption spectroscopy highlight the importance of precision and accuracy in sensor efficiency [32]. While seemingly disparate, both fields deal with deciphering complex patterns. Our technique could potentially refine the algorithms for spectroscopy system measurements. Another study focuses on components like the Fibre Bragg Grating (FBG) [33]. We envisage our models assisting in predicting these components' performance. While direct implementation necessitates further adaptation, integrating our deep learning approach in spectroscopy could enhance calibration accuracy and system reliability. 
6 Conclusion 
     Various approaches of unsupervised machine learning models for image recognition and benchmarks of the results on the CIFAR-10 dataset were investigated in this study. The state-of-the-art pre-trained models’ capability was also tested on the unseen dataset by plotting their knowledge of the 2D manifold via the t-SNE algorithm. This paper also demonstrated the power of DenseNet as a feature extractor when compared to other unsupervised models such as SIFT with HOG, convolutional autoencoder, and ResNets. It was concluded that unsupervised image classification is a well-researched and practiced field in deep learning that can solve the problem of obtaining labeled data by introducing the pre-trained models with clustering techniques such as the DenseNets. Consequentially, decent results are reported on the CIFAR-10 dataset using this approach, whereby the highest achieved accuracy is 68.14%. 
7 Conflicts of Interest
The author(s) declare that they have no conflicts of interest to report regarding the present study.
8 Acknowledgements 
We would like to express our gratitude to the authors of the referenced papers for their valuable contributions to the field of unsupervised learning and image classification. Their pioneering work and insights have greatly influenced our research.